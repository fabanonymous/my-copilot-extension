spring.application.name=my-copilot-extension

server.port=8081

# spring.ai.chat.client.enabled must be set to false if multiple LLMs
# See  Dan Vega - Using Multiple LLMs in Java with Spring AI,
# at https://www.youtube.com/watch?v=bK1MTlEDQvk&t=641s
#spring.ai.chat.client.enabled=false

## OpenAI
spring.ai.openai.api-key=${OPENAI_API_KEY}
spring.ai.openai.base-url=https://api.openai.com
spring.ai.openai.chat.options.model=gpt-4o

## Ollama (local)
#spring.ai.ollama.chat.model=deepseek-r1:7b
